---
title: "[论文解读]Building Natural Language Interfaces to Web APIs"
author: lornd
mathjax: true
date: 2023-08-05 17:56:41
url: NL2API
tags:
---

论文地址：[Building Natural Language Interfaces to Web APIs](https://readpaper.com/paper/2745934983) 。

## 摘要

随着 Web 面向服务架构的发展，应用程序接口（application program interfaces，APIs）正在变成提供对数据、服务和设备的访问越来越重要的方法。我们研究自然语言转换成 API （NL2APIs）问题，并且关注 Web 服务的 Web API。这些 NL2APIs 问题有很多潜在的好处，例如促进将 Web 服务集成到虚拟助手中。

对于一个给定的 Web API ，我们提出了第一个端到端的框架，以建立一个 NL2API 模型。一个关键的挑战在于收集训练数据，即（自然语言命令，API调用）对。从这些数据中，NL2API 模型可以学习到从非结构化的自然语言命令到结构化的 API 调用的映射。通过众包，我们提出了一个理想的为 NL2API 收集训练数据的方法。在众包的过程中，众包工作者们被用来生成各种各样的自然语言命令。为了进一步降低成本，我们还优化了众包工作的流程。更具体地，对于众包工作流程，我们提出了一个理想的分层概率模型，用于指导我们为对于训练 NL2API 模型有高价值的 API 调用分配更多的资源。我们将我们的框架应用在真实世界的 API 上，表明这个框架可以以低成本收集高质量的训练数据，并且从零开始训练出一个具有良好性能的 NL2API 模型。我们同时验证了：我们对众包过程的建模可以提高其效率，这使得通过我们的方法收集到的数据训练出了比一个强 baseline 更好的 NL2API 模型。

## 研究背景

受益于一系列原因，如面向服务的架构（service-oriented architecture, SOA），云计算和物联网（IoT），应用程序接口（APIs）正在虚拟世界和物理世界中发挥着越来越重要的作用。一般来说，API 被用于各种各样的软件，如桌面应用、网站、移动 app 等，这些软件通过图形化用户界面（graphical user interfaces， GUI）为用户提供服务。但是，随着计算领域的发展，有两个问题逐渐显现：

1. 随着计算设备变得更小，更可移动，更智能，需要屏幕变成了一个负担。
2. 为了使用不同的服务和设备，用户必须适应这些服务和设备提供的不同的 GUI ，这增加了用户的学习成本。

这个时候，类似于苹果的 Siri 以及微软的 Cortana 的自然语言界面（Natural language interface, NLI）就成为了一种可能的替代方式。

与以虚拟助手为代表的通用目标 NLI 不同，本文研究的时如何为单独的 Web API 建立 NLI。但是，让虚拟助手逐个集成 Web 服务是非常繁琐的。如果存在一个低成本的方式，能够为 API 建立对应 NLI，集成成本将会极大地下降。在这种情况下，虚拟助手不再需要处理不同的 Web 服务之间不同的界面，而只需要集成单独的 NL2API 。除此之外，NL2API 也可以促进 Web 服务发现、推荐，并且通过降低可用 Web API 及其语法的记忆成本，帮助 API 编程。

对于现阶段的 NLI 研究与应用来说，最关键的挑战是训练数据的收集。由于自然语言的灵活性，用户可以用各种各样的自然语言方式描述一个 API 的调用（如 "Where is the upcoming meeting?" 和 "Find next meeting's location."）。为了学习到这些语言的多样性吗，收集足够多的数据是必要的。已有的研究通常会通过 best-effort 行为收集训练数据，但是如果一个 API 没有被覆盖，或者被覆盖得不够多，就没办法补救；同时，用这种方法收集到的训练数据难以支持多参数的高级命令。因此，为了完全训练 API 的参数化，支持高级 NL 命令，对于一个给定的 API ，如何用活跃的，可定制的方式收集训练数据仍然是一个问题。

## 文章贡献

本文提出了第一个用于从零开始为 Web API 构建 NLI 的端到端的框架。具体包括如下三步：

1. **表示**：Web API 的原始 http 形式包含了很多不相关的，会分散注意力的信息。因此本文提出了Web API 的中间语义表示，以让 NLI 不会受无关细节的干扰。
2. **训练数据收集**：本文提出了一个理想的通过众包收集监督学习训练数据的方法。
3. **NL2API**：本文提出了两个 NL2API 模型，一个是基于检索模型的语言模型，另一个是序列到序列（seq2seq）的神经网络模型。

通过众包工作为 NL2API 收集训练数据的理想方法是本文的一个关键贡献，这个步骤有三个目标：

1. **可定制**：一个人应当确定什么 API、哪些参数、多少训练数据他想要收集。
2. **低成本**：众包工作者的成本比领域专家的成本低很多。
3. **高质量**：训练数据的质量也不能妥协。

通过众包工作的方法有两个主要的挑战：

1. **对于大多数用户来说，拥有高级参数的 API 调用难以理解，需要简化众包工作过程**。因此本文设计了一个 Web API 的中间语义表示，同时设计了一个语法将 API 调用转换为规范的 NL 命令。这样众包工作者就只需要以更自然的方式解释规范命令，从而训练数据收集过程会更少出错。
2. **如何识别并只解释对 NL2API 训练有高价值的 API**？本文为众包过程提出了一个独特的分层概率模型。本文假设 NL 命令是通过对应的 API 调用生成的，并对每一个 API 评估了一个语言模型用于捕捉生成过程。这个模型的基础在于 API 是可以组合的（"unread emails about PhD application" = "unread emails" + "emails about PhD applicationz"）。这样，通过解释一小部分 API 调用，就可以得到能解释所有 API 调用的模型。尽管这个模型并不完美，然而，通过预测未解释 API 调用的语言模型，本文提供了一个所有 API 调用和自然语言与 API 调用的相互关系的整体视角，这让我们有可能优化众包过程。

最后，本文将这个框架用于 Microsoft API 套件中两个已部署的 API 上。展示了通过本文的方法，可以低成本地收集高质量的训练数据。同时众包过程也变得更加高效。在相同的预算下，相较于一个强的 baseline ，可以收集到更好的训练数据，这也让 NL2API 的准确率更高。

## 问题描述（设定）

近年来，REST 架构的 API，即 RESTful API 由于其简便性，变得越来越流行。本文的工作主要聚焦于 RESTful API。对于 RESTful API，采用流行的开放数据协议（Open Data Protoco, OData）。在 OData 中，资源是**实体**，每个实体具有一系列**属性**。除此之外，OData 定义了一个**请求选项集合**以支持高级资源操作。在本文中，定义 http 动作和实体或实体集合的组合为 **API**（如电子邮件研究中的 `GET-Messages`），每个参数化的请求选项（如 `FILTER(isRead=False)`）被称为**参数**；一个 **API 调用**就是有一系列参数的 API 。

NLI 的核心任务是将自然语言命令映射成一些正式的意义表示，如 Web API。为了更好地专注于语义映射，排除一些无关的细节，中间语义表示是一个常用的技巧，而不是直接处理目标表示。本文为 RESTful API 定义了一个中间表示，称之为 API 框架，并与之与框架语义联系起来。一个 API 框架包括五个部分：

- **http 动作**和**资源**：这是 RESTful API 的基本元素。
- **返回类型**：这在 API 组合的情况下非常有用，即将多个 API 组合起来使用，以完成更复杂的任务。
- **必需参数**：经常被用在 `PUT` 请求和 `POST` 请求中。
- **可选参数**：经常用于 `GET` 请求以指定需要的细节信息。

当没有必需参数时，序列化 API 框架（如 `GET-messages{FILTER(isRead=False), SEARCH("PhD application"), COUNT()}`）。一个 API 框架可以被唯一地转换为一个真实的 API 调用。必要的上下文信息如用户 ID、位置和日期时间会在会话的过程中被填充。

有了这些定义，在本文的后半部分，API 框架和 API 调用表示的意义是相同的。

## 解决方法

本文首先生成 API 调用并且通过一个简单的语法将其转换为规范的命令，之后雇佣众包工作者解释这些规范命令。基于 API 调用的组合特性，本文为众包过程提出了一个分层概率模型，同时提出了一个算法以优化众包过程。最后，为了验证提出的框架，本文使用其他 API 领域内两个成功的模型进行了测试。

### API 调用与规范命令

本文通过 API 规范生成 API 调用。除了请求选项和实体属性等模式项目以外，还需要属性值以生成 API 调用，但是属性值是无法从 API 规范中获得的。因此有如下处理方式：

- 对于可遍历的属性值（如 bool 类型），遍历所有可能的值（如 True/False）。
- 对于有无穷多取值的属性值（如 Datetime），使用一些具有代表性的值（如：今天、这周等）。

在将 API 框架转换为一个真实的 API 调用时，会根据上下文选择合适的值。

我们可以很容易地遍历所有请求选项、属性、属性值的组合来生成 API 调用，并且用一些简单的启发算法来删掉那些不是很合理的组合（如 `TOP` 必须被用在一个有序列表中，所以必须与 `ORDERBY` 一起使用）。但是，因为组合爆炸，对于每个 API 依然有大量的 API 调用。

用户的平均水平并不能理解 API 调用，因此需要将 API 调用转换为规范命令。本文定义了一个 API 专用词典，和一个 API 通用语法。词典告诉了每个项目（http 动词，实体，属性和属性值）的词汇形式和语法类别。如下图所示：

{% gallery %}
![规范命令语法](/images/NL2API/canonical_command.png)
{% endgallery %}

值得注意的是：即使这个词典是每个 API 专用的，并且必须由 API 的管理者提供，但是语法是通用的，并且可以直接或者稍加修改地复用于遵循 OData 协议的任何 RESTful API 。

语法确定了如何一步一步将 API 调用转换为规范命令。语法是一系列规则，其形式为：$\langle t_1,t_2,\cdots, t_n\to c[z]\rangle$ ，其中 $\{t_i\}_{i=1}^n$ 是 token 序列，$z$ 是一个（部分）API 调用，$c$ 是语法类别。值得注意的是：句法类别允许条件派生。例如：`VP[x = False]` 同时符合规则 B2 和 B4 ，这个时候就通过 `x` 来判断到底使用哪个规则。

### 语义网格

接下来，本文为众包过程提出了一个分层概率模型，用于之后决定要解释哪些 API 。这是第一个用于 NLI 众包过程的概率模型，其特点在于：对自然语言和形式意义表示之间的关系进行建模这一独特而有趣的挑战。

一般来说，形式意义表示，尤其是 API 调用，本质上是复合的（如 `GET-Messages {COUNT(),FILTER(isRead=False)}` 是由 `GETMessages{FILTER(isRead=False)}` 和 `GET-Messages {COUNT()}` 复合而成）。本文的关键想法在于：这些复合性质可以被用来建模众包过程。

首先基于 API 调用的参数集给出复合的定义：

> 定义（复合）：给定一个 API 及一系列 API 调用 $z_1, z_2, \cdots, z_{n+1}, n > 1$ ，记 $z$ 的参数集合为 $r(z)$ ，那么称 $z_{n+1}$ 是由 $\{z_1, z_2, \cdots, z_n\}$ 复合而成，当且仅当 $\{r(z_1), r(z_2), \cdots, r(z_n)\}$ 是 $r(z_{n+1})$ 的一个划分。

基于 API 调用之间的复合关系，可以把一个 API 的所有 API 调用组织成等级结构。将所有有相同数量参数的 API 调用表示为同一层中的节点，复合关系表示为层与层之间的连边。这被称为**语义网格**。如下图所示：

{% gallery %}
![语义网格](/images/NL2API/semantic_mesh.png)
{% endgallery %}

本文假设相同 API 调用 $z$ 对应的自然语言表示是通过随机过程生成的，即一个语言模型 $\theta^z$ 。简单起见，关注单词概率，即 $\theta^z: p(w\ |\ z), w\in {\mathcal V}$ ，其中 ${\mathcal V}$ 是词汇表。所使用的不是标准的一元语言模型，而是伯努利袋分布（Bag of Bernoulli, BoB）。每个伯努利分布对应一个随机变量 $W$ ，表示单词 $w$ 是否出现在由 $z$ 生成的自然语言表示中。而 BoB 分布就是所有单词的伯努利分布的袋子 $\{p(W|z)\}$ ，也被记作 $p_b(w|z)$ 。

假设已经为 $z$ 收集了一个自然语言表示 $u^z$ 的（可重）集合,BoB 分布的最大似然估计是包含单词 $w$ 的自然语言表示的比例：

$$p_b(w|z) = \dfrac{|\{u|w\in u, u\in u^z\}|}{|u^z|}, \forall w\in {\mathcal V}$$

在语义网格上，有三种基本的节点级别操作：解释（annotate），组合（compose）和插值（interpolate）。

#### 解释（annotate）

通过众包工作为节点 $z$ 表示的规范命令做出自然语言解释 $u^z$ ，并且通过最大似然估计法评估经验分布 $\theta^z_{em}$ 。

#### 组合（compose）

尝试基于节点的组合推理出一个语言模型，这导致了期望分布 $\theta^z_{ex}$ 的产生。假设 $z$ 由 $\{z_1,z_2,\cdots,z_n\}$ 组合而成，那么，如果认为对应的自然语言描述也遵循组合性质，则 $\theta^z_{ex}$ 会与 $\{\theta^{z_1}, \theta^{z_2}, \cdots, \theta^{z_n}\}$ 相关。即：

$$\theta^z_{ex} = f(\theta^{z_1}, \theta^{z_2}, \cdots, \theta^{z_n})$$

这里 $f$ 是组合函数，$\theta^z_{ex}$ 是 $p_b(w|z)$ 。对于 BoB 分布，组合函数为：

$$p_b(w|z) = 1 - \prod\limits_{i=1}^n (1 - p_b(w|z_i))$$

即，假设 API 调用 $z_i$ 对应的自然语言表示为 $u_i$ , $\{u_i\}_{i=1}^n$ 组合形成了 $u$ ，那么 $w$ 不出现在 $u$ 中的充要条件是 $w$ 不出现在任何一个 $u_i$ 中。当 $z$ 有多个组合时，对于每个组合分别计算 $\theta^z_{ex}$ 再取平均。而对于标准一元语言模型，单词概率的规范化涉及到自然语言表示的长度，反过来又涉及到 API 调用的复杂程度，这使得最开始的归因不再成立，因此本文使用了 BoB 分布。

但是，自然语言表示并不总是组合在一起。例如：规范意义表示中的多个项目可以被压缩成一个单词或短语（如 `TOP(1)` 、`FILTER(start>now)` 、`ORDERBY(start,asc)` 三者合起来对应一个单词 `next`），这种现象被称作为亚词复合性（sublexical compositionality）。但是，如果不解释 API ，就无法获得这样的信息，这就变成了一个”先有鸡还是先有蛋“的问题。在这些信息缺失的情况下，引入**自然语言描述遵循 API 调用的组合关系**这一假设是非常合理的，这让我们能够计算期望分布。

值得注意的是：这个假设只被用于建模用于数据收集的众包过程。在测试阶段，真实用户生成的自然语言解释可以违反这一假设。如果所收集的训练数据涵盖了这些非组合的情况，那么自然语言接口就有可能处理这些情况。

#### 插值（interpolate）

综合所有可获得的有关 $z$ 的信息，即 $z$ 的自然语言解释和继承于组合的信息，通过对 $\theta^z_{em}$ 和 $\theta^z{ex}$ 进行插值，我们可以得到一个更加准确的 $\theta^z$ 的估计：

$$\theta^z = \alpha \theta^z_{em} + (1-\alpha)\theta^z_{ex}, 0\le \alpha\le 1$$

平衡参数 $\alpha$ 用于控制当前节点的解释（准确但是信息很少）与从组合中继承的信息（可能不那么准确，但是信息很多）之间的权衡。在某种意义上，$\theta^z_{ex}$ 与语言模型中平滑操作的作用类似，以在解释数据不足时更好地估计概率分布。对于没有组合的根节点，$\theta^z = \theta^z_{em}$ ，对于没有解释的节点，$\theta^z = \theta^z_{ex}$ 。

最后介绍更新语义网格的算法，即：为所有的 $z$ 计算 $\theta^z$ ，即使只有一小部分的节点有解释。首先假设所有的已解释的节点其 $\theta^z_{em}$ 值已被更新。接下来自上而下逐层依次计算每个节点的 $\theta^z_{ex}$ 和 $\theta^z$ 。上层节点必须先被更新，以使得下层节点的期望分布能够被计算。当我们遍历完所有的根节点，所有节点的 $\theta^z$ 就都被计算出来了。

{% gallery %}
![语义网格更新算法](/images/NL2API/semantic_mesh_update.png)
{% endgallery %}

### 众包工作优化

对于众包过程的优化，本文提出了一个不同的传播策略。给定一个语义网格，假设节点集合为 $Z$ ，我们的目标是为众包工作者反复选择一个节点子集 $\bar{z} \subset Z$ 让他们解释。如果将至今为止已被解释的节点集视为**状态**，那么我们需要找到一个**策略** $\pi: Z \backslash \bar{z} \to {\mathbb R}$ ，基于当前的状态为每一个未标记的节点进行评分。

假设我们已经有了一个好的策略，那么可以通过算法 2 对语义网格进行分析：

{% gallery %}
![语义网格分析](/images/NL2API/semantic_mesh_annotate.png)
{% endgallery %}

首先，解释所有的根节点以估计所有节点的分布（line3）。接下来，在每一次迭代的过程中，首先更新所有的节点分布（line5），根据当前语义网格的状态计算策略（line6），贪心地选择未被解释的节点中分数最高的节点（line7），解释所选择的节点会导致一个新的状态（line8）。

广义地说，我们所研究的问题可以被分类为主动学习问题，因为它们的目标都是相同的：选择样本的一个子集进行解释，以获得一个可以提升模型性能的训练集。但是一些关键的差别使得经典主动学习不能直接应用在本文的问题中。在经典主动学习中，模型尝试学习一个映射 $f:X\to Y$ ，其中 $X$ 是输入样本空间，包括一小部分标记了的样本，和一大部分未标记的样本，$Y$ 是一小部分分类标签的集合。模型评估每个未标记样本的信息量，选出最具有信息量的样本让众包工作者进行标注。然而，在本文的问题中，解释工作恰好反过来了。我们需要从 $Y$ ，即 API 调用空间中选择一个实例，让众包工作者用 $X$ ，即自然语言空间对其进行标注。同时，我们并不希望方法只适用于一个模型，因此我们提出了一个新的解决方法。

我们的目标是量化每个节点的信息量。即希望不同的 API 调用之间足够具有辨识度。在语义网格中，它意味着不同节点之间的分布 $\theta^z$ 足够发散。首先将 $\theta^z$ 表示为 $n$ 维向量 $(p_b(w_1|z),\cdots,p_b(w_n|z))$ ，其中 $n = |{\mathcal V}|$ 是词汇表的大小。本文使用 L1 距离来衡量向量之间的距离，记 $d(z_i,z_j)=d(\theta^{z_i},\theta^{z_j})$ ，即两个节点分布之间的距离。一个显然的优化目标是最大化所有节点两两之间的距离之和，但是这种做法既计算复杂，又没有必要。因此我们只关注带来最多的混淆信息的节点对，即距离最近的节点对：

$$\Theta = \sum\limits_{i=1}^Kd(z_i, z_i')$$

这里的 $\{(z_1, z_1', z_2. z_2',\cdots, z_k, z_k')\}$ 是最近的 $K$ 个节点对。

我们认为：如果一个节点有可能为 $\Theta$ 的提升做出更大的贡献，就认为该节点的信息量更大。本文提出了一个**差异传播策略**以量化这种贡献。对于距离很小的一对节点，检查它们的祖先：

- 如果父节点是两个节点共同的父节点，那么这个节点会获得较低的分数，因为对这个父节点进行解释会对两个子节点的信息造成相似的影响。
- 否则这两个父节点应该获得较高的分数，且父节点距离子节点越近，分数就应该越高。

{% gallery %}
![差异传播示例](/images/NL2API/differential_propagation.png)
{% endgallery %}

在图 6 中，可以将 $z_{12}$ 看成“unread emails about PhD application”，将 $z_{23}$ 看成“how many emails are about PhD application”，而$z_2$ 就是“emails about PhD application”。

算法描述如算法 3 和算法 4 所示：

{% gallery %}
![算法 3](/images/NL2API/alg3.png)
{% endgallery %}

{% gallery %}
![算法 4](/images/NL2API/alg4.png)
{% endgallery %}

### 模型测试

本文使用了两种模型对 NL2API 框架进行测试：基于 LM 的检索模型和 seq2seq 解释模型。

#### 基于 LM 的检索模型

将 NL2API 视为检索问题，就可以将检索模型应用在测试中。

给定一个输入的自然语言表述 $u$ ，我们的任务是在语义网格中找到与 $u$ 最匹配的 API 调用 $z$ 。首先将 Bob 分布转换为词元语言模型中单词的分布：

$$p_{lm}(w_i|z) = \dfrac{p_b(w_i|z) + \beta}{\sum_{j}^{|{\mathcal V}|}p_b(w_j|z) + \beta|{\mathcal V}|}$$

这里使用了加一平滑（拉普拉斯平滑）技巧，用于防止零概率的发生，$0\le\beta\le1$ 是平滑参数，$\beta$ 越大，说明给予未出现的单词的权重就越高。基于词元模型的概率分布，可以通过对数似然函数来计算每个 API 调用的分数（假设先验分布为均匀分布）：

$$\log p(z|u) \propto \log p(u|z) + \log p(z) \propto \sum\limits_{i}^{|u|}\log p_{lm}(w_i|z)$$

得分最高的 API 调用就是模型的输出。

#### seq2seq 解释模型

seq2seq 模型所做的事情是：给定一个输入序列 $x=(x_1,x_2,\cdots, x_T)$ ，对于所有可能的输出 $y=(y_1,y_2,\cdots, y_{T'})$ ，估计其条件概率 $p(y|x)$ 。其中序列的长度 $T$ 和 $T'$ 不一定需要相同，并且可以有多种取值。因此这个模式很适用于 NL2API 问题：将自然语言表述视为 $x$ ，规范化的 API 调用或者规范命令视为 $y$ 。在本文中，将规范命令视为 $y$ ，以将问题转换为一个转述问题。

对于 encoder ，使用有门控循环单元（GRU）的循环神经网络（RNN），将 $x$ 编码成一个固定维度的向量：

$$h_0 = GRU(x)$$

而 decoder 也是 GRU，将 $h_0$ 作为初始状态，一步一步处理序列 $y$ 以生成状态序列：

$$h_t = GRU(y_t, h_{t-1})$$

输出层将每个 decoder 的状态作为输入，将词汇表 $\mathcal V$ 中每个单词的概率分布作为输出。在这一层，简单地使用仿射变换 + softmax 激活函数的形式：

$$
\begin{align*}
    o_t & = \{p(o_t = w)|w\in{\mathcal V}\} \\
        & = softmax(W_oh_t + b_o)
\end{align*}$$

最后的条件概率通过如下方式进行计算：

$$p(y|x) = \prod\limits_{t=1}^{T'} p(o_t=y_t)$$

API 调用的得分就是其对应规范命令的条件概率。可以参考论文 [Sequence to Sequence Learning with Neural Networks](https://readpaper.com/paper/2949888546) 获取更多模型训练的细节。

## 实验验证

本文的实验需要回答以下三个问题：

1. **RQ1**：通过本文提出的框架，可以以合理的低成本收集到高质量的数据吗？
2. **RQ2**：相较于最大似然估计，语义框架对语言模型的估计是否更加准确？
3. **RQ3**：差异传播策略是否让众包过程更加高效？

### 众包过程

本文在微软的两个 API 上进行了实验：`GET-Events` 和 `GET-Messages`，这两个 API 分别为用户提供日历活动和邮件的高级检索功能。对于每个 API ，我们通过遍历所有不超过 4 个参数的 API 调用，以构建语义网格。API 调用的分布如表 2 所示：

{% gallery %}
![API 调用分布表](/images/NL2API/table2.png)
{% endgallery %}

为了实验的灵活性，本文为每个 API 调用添加了最多三个参数的注释。在每个实验中，只使用参数的子集进行训练。每个 API 调用都用 10 句话进行解释，每句解释的花费为 10 美分。每位众包工作者平均花费 44 秒以转述规范化命令，因此从一个众包工作者身上，每小时只需花费 8.2 美元，就可以获取 82 个训练样本，这个成本可以认为是**合理的低成本**。对于数据的质量，人工检查了 400 条自然语言注释，我们发现错误率为 $17.4\%$ ，主要的错误原因为：忘记了一些参数，或者误解了一些参数的意思。这两种原因大约各占一半。该错误率与其他众包算法不相上下，因此 **RQ1** 的回答是肯定的。通过雇佣独立的众包工作者进行后期验证，数据的质量可以得到进一步提高。

除此之外，我们还从整个语义网格中随机挑选了一个测试集，对其中的 API 调用进行注释，其中也包括有 4 个参数的 API 调用。每个 API 调用先用 3 句话分别对其进行 3 次解释，剔除错误的解释之后，测试集中 API 调用及解释的分布如表 3 所示：

{% gallery %}
![测试集 API 调用及解释分布表](/images/NL2API/table3.png)
{% endgallery %}

测试集中的所有解释都不在训练集中出现，并且测试集中甚至会出现不在训练集中的 API 调用，这使得测试过程极具挑战性。

### 实验设置

本文所选择的测试指标为准确率，即对于测试集中的自然语言注释，预测正确的比例。

如果没有特殊说明，平衡参数 $\alpha = 0.3$ ，LM 的平滑参数 $\beta = 0.001$ 。在差异传播过程中所使用的节点对的数量 $K$ 被设置为 $10$ 万。对于 seq2seq 模型，编码器和解码器所使用的状态维度被设置为 $500$ 。这些参数的选择都是基于对验证集的研究（独立于测试集）。

出了对众包过程优化有用以外，作为 NLI 众包过程中此类型的第一个模型，语义网格也有其自身的技术优势，因此接下来将分别评估语义网格和优化算法。

### 语义网格测试

语言模型的质量可以通过其准确率体现：估计越准确，表现就越好。因此本实验使用准确率作为指标。同时，本实验使用三个不同的训练集，对应不同的被注释的节点的集合：ROOT 是所有的根节点；TOP2 是 ROOT 加上第二层的所有节点；TOP3 是 TOP2 加上第三层的所有节点。不同数据集的设置使得我们可以通过不同数量的训练数据来评估语义网格。实验结果如表 4 所示：

{% gallery %}
![语义网格测试实验结果](/images/NL2API/table4.png)
{% endgallery %}

对于基线 LM 模型，使用最大似然估计（MLE）进行语言模型的估计，即对于所有已注释的节点，使用 $\theta^z_{em}$ ，对于未被注释的节点，使用均匀分布，这种情况下效果很差，尤其是当注释节点的数量很小时。出现这种情况的原因时：MLE 不能够提供任何有关于未注释节点的信息。

而当我们将组合操作（COMPOSE）加到 MLE 上时，就可以为未注释节点估计期望分布 $\theta_{ex}$ ，但是对于有注释的节点，依然使用 $\theta_{em}$ 。这为 API 和训练集带来了显著的改进，仅仅使用 16 个已注释的 API 调用（ROOT），使用语义网格的简单 LM 模型可以比使用 100 多个已注释 API 调用（TOP2）的最先进的 seq2seq 模型表现得优秀很多，并且表现与使用约 500 个已注释 API 调用（TOP3）的 seq2seq 模型性能接近。这些结果表明利用组合操作估计的语言模型相当准确，并且凭经验证明了自然语言组合性假设的合理性。

同时可以观察到：`GET-Events` 任务比 `GET-Messages` 任务更难，因为 `GET-Events` 任务包括更多富有挑战性的与时间相关的命令。事件可能在未来或者过去发生，但是消息只会出现在过去。

当我们使用更多的训练数据时，`LM + COMPOSE` 的性能在下降，这说明仅仅使用 $\theta_{em}$ 解决问题是不够的，需要结合 $\theta_{em}$ 和 $\theta_{ex}$ 。因此，当我们对 $\theta_{em}$ 和 $\theta_{ex}$ 进行插值（INTERPOLATE）操作时，除了 ROOT 数据集，效果都得到了提升。因为 ROOT 数据集中的节点都不同时拥有 $\theta_{em}$ 和 $\theta_{ex}$ 两个数据。与组合操作（COMPOSE）相反，使用的训练数据越多，插值操作（INTERPOLATE）带来的提升越明显。

综上所述：语义网格为 MLE 基线带来了很大的提升，因此 **RQ2** 的回答也是肯定的。

实验结果中的最佳准确率在 $0.45$ 到 $0.6$ 之间，这并不高，但是与知识库 NLI 中最先进的方法不相上下。这反应了问题的困难程度，因为要从成千上万个 API 调用中准确地找到最好的 API 调用。**为 API 调用收集更多的自然语言解释，或者使用更先进的模型（如有 Attention 机制的双向 RNN）可能可以提升性能，这些可以是未来的工作。**

接下来基于 LM 模型的表现分析语义网格中两个超参数：自然语言数量 $|u|$ 和平衡参数 $\alpha$ 的作用。实验时，当 $|u| < 10$ 时，自然语言描述随机选择，重复进行 10 次实验取结果的平均值。实验结果如图 7 所示：

{% gallery %}
![超参数实验结果](/images/NL2API/fig7.png)
{% endgallery %}

不出意外地，虽然增长逐渐变缓，随着每个节点自然语言注释的增加，模型效果也在逐渐变好。因此如果成本可以承受，为每个节点获取更多的自然语言注释通常是一个好主意。

另一方面，当 $\alpha \in [0.1, 07]$ 时，模型的效果受 $\alpha$ 的值影响很大。随着注释节点的增多，$\alpha$ 的影响也在增大，这是可以预见的，因为插值操作只影响注释节点。

### 众包优化

该实验的目的是评测本文提出的差异传播策略（diferential propagation, DP）对众包优化的影响。差异传播策略在迭代的过程中选择需要注释的 API 调用。在每一轮迭代中，选择 50 个 API 调用，进行注释，然后两个 NL2API 模型会在逐渐变多的注释数据上进行训练，并且在测试集中进行测试。本次实验使用基础的 LM 模型，这与语义网格是相互独立的。一个更好的众包策略应该在相同数量的注释下获得更好的模型效果。在此实验中，并不通过众包动态注释节点，而是使用已经收集的注释作为候选池，因此所有的策略只会从最多拥有三个参数的 API 调用中进行选择。

基线策略采用广度优先策略（Breadth First, BF），从上往下逐层对语义网格中的节点进行注释。高层的 API 调用通常是更加重要的，因为它们组合形成了低层的 API 调用。

{% gallery %}
![众包优化策略实验结果](/images/NL2API/fig8.png)
{% endgallery %}

实验结果如图 8 所示，可以看到：对于两种 API 的两种NL2API 模型，总体来看，DP 有着更好的效果。当我们只注释 300 个 API 调用时，对于 seq2seq 模型，DP 策略在两种 API 上带来了超过 $7\%$ 的绝对准确率提升。当候选池中的注释几乎全部用完的时候，两种算法都会收敛，这也是期望中的结果。实验结果表明：DP 策略能够为 NL2API 的训练过程辨别出高价值的 API ，因此 **RQ3** 的回答是肯定的。
